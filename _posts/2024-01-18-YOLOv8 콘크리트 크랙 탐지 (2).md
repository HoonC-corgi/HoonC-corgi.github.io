---
published: false
---

**YOLOv8 Concrete Crack Detection using Instance Segmentation #1**
-----

## Review


 현장실습이 바빠 한동안 글을 쓰지 못했다. 오늘은 지난 게시글의 연장선을 이어 가려 한다.

[이전 게시글](https://hoonc-corgi.github.io/2023/11/24/YOLOv8-콘크리트-크랙-탐지.html)

 지난 글에서는 학습을 위한 기본적인 환경 세팅을 진행하였다. 이번 게시글에서는 구체적인 학습 환경, 학습 결과, 모델을 이용한 예측을 개괄적으로 살펴 볼 것이다. 처음 이 프로젝트를 시작하게 되고 나서 YOLO를 알게 되었고, 이를 활용하기 위해 YOLOv3부터 v5, v8으로 오기까지 정말 많은 고생을 했다. 버전마다 상이한 백본 구조나 메소드 구조, 입력 층의 요구 차원 등등,, backward compaitibility가 없었고, 텍스트 ai만 잠깐 공부하고는 급하게 시작한 비전 ai 프로젝트였기 때문에 비전 ai에 대한 근본적인 개념에 대한 이해와 내가 필요로 하는 버전의 YOLO 사용법을 함께 공부해야 했고, 개념을 혼동한다던가, 레퍼런스를 잘못 찾아 5 메소드를 3에 사용하면서 왜 안 되나,, 좌절하고는 했다. ~되는 게 이상하지 ㅋㅋ~

 하지만 막히고 다른 방법으로 시도하는 것을 이과정에서 반복하며 체득했기 때문에, 높은 수준은 아님에도 현재 정도의 이해도를 갖게 되었다. 이것이야 말로 이 블로그에 쓰면 좋을 이야기들이지만, 당시에는 문서 형태의 기록을 남긴다 거나, 과정 중의 사진을 찍어 놓지는 않았기에 이를 일일이 기억하며 쓰기는 불가능할 것 같다. p.s. 아래 내 노력의 흔적,,
 
 ![노력의 흔적,,](https://github.com/HoonC-corgi/Crack_Detection_using_YOLOv8_Instance_Segmentation/assets/118245330/85b1f77b-75b9-48c9-a408-5e29b1ba301b)


 여튼 본문을 시작해 보겠다.

-----


ai 모델 학습에서 필수적인 요소는 아래와 같다.

   1. 모델
   2. 학습 데이터
   
   나도 처음에는 간단하다고 생각했다. 하지만, 실제로 프로젝트의 완성에 다가온 현재 시점에서 생각해 보면 이는 지나치게 포괄적이다. 모델의 경우 나의 상황에 적절한 모델이 무엇인가를 찾아야 하고, 어떻게 사용해야 하는지를 알아야 하며, 어떠한 구조인지를 정확히 이해해야만 한다. 학습 데이터는 train, valid, test 셋에서의 각 비율을 몇으로 둘 것인지부터가 시작인 것 같지만, 나는 대부분의 시간을 이가 아닌 학습 데이터의 확보 및 정제, 레벨링에서 써야만 했다. 이렇게 학습이 완료되면, 학습한 모델을 어떻게 사용할 것인지에 대한 application 영역에 다가가지만, 이 단계에서도 복잡한 여러 과정을 거쳐야만 한다. 이부분은 추가적인 글을 통해 작성해 보겠다.

## 모델 학습
  - 모델
   프로젝트에 사용한 모델은 ultralytics 사의 YOLOv8n-seg 모델이었다. YOLO 모델은 객체 탐지가 빨라 실시간성을 충족하여 부상한 비전 모델이다. 나는 Microsoft사의 AR Machine인 HoloLens에서 이를 구동하길 원했기 때문에 실시간성이 중요했고, 이를 선택했다.
  
  
  ![hololens2](https://github.com/HoonC-corgi/Crack_Detection_using_YOLOv8_Instance_Segmentation/assets/118245330/d4ab809d-5874-4a69-b1d6-17ff0d832bbc)

    
   
   
   내가 사용한 모델의 이름을 풀어보면, YOLO: 모델 이름, v8: 8버전, n: nano 버전, seg: Instance Segmentation Task를 수행하는 모델임을 의미한다. YOLO 모델 자체에 대한 자세한 사항은 추후에 공부하는 게시글을 정리해서 올리게 되면 다뤄보도록 하겠다.