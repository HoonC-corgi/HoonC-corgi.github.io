---
published: True
---

# **YOLOv8 Concrete Crack Detection using Instance Segmentation #2**
## - About Preparing a Training Dataset

-----

## Review


현장실습이 바빠 한동안 글을 쓰지 못했다. 오늘은 지난 게시글의 연장선을 이어 가려 한다.

[이전 게시글](https://hoonc-corgi.github.io/2023/11/24/YOLOv8-콘크리트-크랙-탐지-(1)-학습-환경-구축에-관하여.html)

지난 글에서는 학습을 위한 기본적인 환경 세팅을 진행하였다. 이번 게시글에서는 구체적인 학습 환경과, 학습 이전 데이터 수집 및 정제와 같은 데이터 셋 준비 단계에서 내가 느낀 바와 이해한 것에 대하여 작성해 볼 것이다.  
지금에서야 이렇게 글도 작성하며 다시 복습하고 정리도 할 수 있게 되었지만, 텍스트 ai만 잠깐 공부하고는 급하게 시작한 비전 ai 프로젝트였기 때문에 비전 ai에 대한 근본적인 개념에 대한 이해와 내가 필요로 하는 버전의 YOLO 사용법을 함께 공부해야 했고, 개념을 혼동한다던가, 레퍼런스를 잘못 찾아 5버전의 메소드를 3버전에 사용하면서 "왜 안 되나,,"하며 좌절하고는 했다. ~~되는 게 이상하지 ㅋㅋ~~  


기본적으로 YOLO를 사용할 줄 알겠다 싶을 때가 되어서는 가령, 버전마다 상이한 백본 구조나 메소드 구조, 입력 층의 요구 차원들에 대한 이해, backward compaitibility에 막히는 등 YOLOv3부터 v5, v8으로 오기까지 정말 많은 고생을 했다.  
하지만 막히고 다른 방법으로 시도하는 것을 이과정에서 반복하며 체득했기 때문에, 높은 수준은 아님에도 현재 정도의 이해도를 갖게 되듯 하다.  ~~항상 느끼지만 나의 Problem Solving Ability는 들이박고 깨지면서 앞으로 가기인 것 같다.~~
이것이야 말로 이 블로그에 쓰면 좋을 이야기들이지만, 당시에는 문서 형태의 기록을 남긴다 거나, 과정 중의 사진을 찍어 놓지는 않았기에 이를 일일이 기억하며 쓰기는 불가능할 것 같다.    
p.s. 아래는 내 노력의 흔적,,  



![노력의 흔적](https://github.com/HoonC-corgi/Convolution_Filter_Application/assets/118245330/a5de9e4e-610c-4fd0-9c88-b88b12295f74)


여튼 본문을 시작해 보겠다.


---   

ai 모델 학습에서 필수적인 요소는 아래와 같다.

1. 모델
2. 학습 데이터

나도 처음에는 간단하다고 생각했다. 하지만, 프로젝트의 완성에 다가온 현재 시점에서 생각해 보면 이는 지나치게 포괄적이다. 실제로 모델을 활용하기 위해서는  

**1. 나의 상황에 적절한 모델이 무엇인가를 찾아야 하고,**   
**2. 어떻게 사용해야 하는지를 알아야 하며,**   
**3. 어떠한 구조인지를 정확히 이해해야만 한다.**  


학습 데이터는 train, valid, test 셋에서의 각 비율을 몇으로 둘 것인지부터가 시작인 것 같지만, 나는 대부분의 시간을 이가 아닌 학습 데이터의 확보 및 정제, 레벨링에서 써야만 했다.  
이렇게 학습이 완료되면, 학습한 모델을 어떻게 사용할 것인지에 대한 application 영역에 다가가지만, 이 단계에서도 복잡한 여러 과정을 거쳐야만 하므로 이부분은 추가적인 글을 통해 작성해 보겠다.

---

## 모델 학습
#### 모델


![HoloLens2](https://github.com/HoonC-corgi/Convolution_Filter_Application/assets/118245330/b77c4069-9b51-49e1-bc04-dcb6a2aa7609)

나는 초기 프로젝트 계획에 따라 Microsoft사의 AR Machine인 HoloLens2에서 이를 구동하길 원했기 때문에 실시간성이 중요했고, 이를 기준으로 모델을 찾아 보았다.  
개중 ultralytics사의 YOLO 모델은 객체 탐지가 빨라 실시간성을 충족하여 부상한 비전 모델으로, YOLO 안에서도 모델의 버전과, 용도에 따른 규모의 차이, 기능인 'Task'에 따라 여러 종류로 나뉘었고, 나는 YOLOv3, v5, v8의 Object Detection, Segment Instance, nano, x 모델 등을 직접 사용해 본 후 활용성, 합목적성, 난이도 등을 고려하여 최종적으로 _**YOLOv8n-seg**_ 모델을 선택하였다. 



내가 사용한 모델의 이름을 풀어보면, YOLO: 모델 이름, v8: 8버전, n: nano 버전, seg: Instance Segmentation Task를 수행하는 모델임을 의미한다. YOLO 모델 자체에 대한 자세한 사항은 추후에 공부하는 게시글을 정리해서 올리게 되면 다뤄보도록 하겠다.

---

#### 학습 데이터
###### 데이터 수집

최초에는 학습 데이터를 마련하기 위해 직접 사진을 찍으러 다녔다. 건물 지하 주차장의 외벽, 주변의 구축 건물, 현장실습으로 다니는 회사의 벽, 참 많은 곳을 둘러다녔다.  
길을 걸어갈 때에는 보이던 균열들이 막상 찾아보니 많지 않아 고민 하던 중 학과 건물 바로 뒤에 위치한 전기관에 가서 홀로 나름의 데이터 선별을 거쳐 사진을 찍어 오니 28장 쯤 되었다.  
아무리 비전 ai가 처음이었던 나라고 하여도, 이정도 데이터로는 택도 없음을 알고 있었다. 그렇게 잔머리를 굴리던 중 ***"사진을 45도 정도만 기울여도 다른 데이터가 아닌가?"*** 싶은 생각이 들었다.  
아무리 AI라고 한들, 이는 지도 학습이었고, 내가 제공하는 사진을 스스로 기울여 가며 학습을 하는 것은 아니기에 가능하다고 생각했다.  
그렇게 우연히 비전 ai의 **Data preprocessing, 데이터 전처리** 기법, **Data Augmentations, 데이터 증강** 기법에 관심을 가지게 되었다.  
처음에는 이것의 활용 여부는 선택이라 생각했지만, 나와 같이 데이터가 부족한 경우나 데이터를 정제해야 할 때 이는 필수적임을 알게 되었다.  
"그러한 경우가 아니라면 선택의 영역인가?" 라고 생각할 수 있지만, 모델의 퍼포먼스를 위해서라도 ***<u>대부분의 학습에서 데이터 정제는 필수적이다.</u>*** 


![applying augmentation](https://github.com/HoonC-corgi/Convolution_Filter_Application/assets/118245330/bcaf74d3-ccc8-4c0a-a55a-0598253c0ccb)

나는 그렇게 28장의 사진과 공공 데이터 일부를 취합하여 roboflow의 기능을 통해 수없이 전처리 -> 증강 -> 임의 학습 -> 평가하며 현재 나의 상황에 최적이라 판단 되는 조합을 찾았다.  

![data preprocessing](https://github.com/HoonC-corgi/Convolution_Filter_Application/assets/118245330/b8134eea-6481-49b2-aa61-1b0b765b772c)

- **Preprocessing-Resize**  
YOLOv8의 경우 640, 640의 크기를 기대하기 때문에, Resize 해주었다.


- **Augmentations**  
  - **Flip**  
  데이터를 수집할 때 습관적으로 정방향에 수평을 맞추어 찍은 탓에 수평 수직 대칭을 해 주었다.
  + **Crop**  
  전기관 벽면 데이터를 수집함에 있어서 높이 때문에 정확히 촬영하기 어려운 경우가 있어, 축소하지는 않고, 확대한 사진도 추가해 주었다.
  - **Exposure**  
  전기관의 경우 벽면이 회색인 경우가 많았고, 크랙은 검은색이 대부분이었기에, 노출 값을 조정해 주어 해당 경우에 대한 과적합을 줄일 수 있을 것으로 보았다.
  + **Noise**  
  노이즈의 경우, 라벨링 된 가장자리의 인접 픽셀에 의도적으로 노이즈를 주어, 학습 후에 보다 정밀한 Masking에 도움이 된다. 특히 균열의 경우 규칙적이거나, 선형적이지 않은 가장자리가 많으므로 도움이 될 것으로 보았다.
  - **Mosaic**  
  모자이크는 하나의 이미지를 여러 개의 작은 타일로 조각내어 이를 무작위 재조합하여 학습함으로써 다양한 위치와, 배경, 조명 등의 변수에 대해 안정성을 가질 수 있도록 한다. 다양한 변수들을 학습하기 힘든 소규모 데이터 셋에서 특히 더 큰 효과를 내므로, 이는 나에게 최적이었다.  


위 방식으로 3,000장의 데이터 셋을 준비하였다.




###### 데이터 라벨링

**Data Labeling**은 이름 그대로 각 데이터에 레이블링을 해주는 작업이며, 이는 모델의 입장에서는 교과서 정도의 의미를 갖는다. 즉, 모델은 데이터의 label을 통해서 이것이 사람인지, 아닌지 등을 판단하는 것이다.  
이러한 데이터 라벨링은 지도 학습, 분류 모델에서 필수적이며 데이터 라벨링의 퀄리티 또한 모델의 퍼포먼스에 큰 영향을 미친다. 교과서가 잘못 편찬 되었다면, 이를 공부한들 지식이 늘어나지도, 수능 시험을 잘 칠 수도 없는 것과 같이 지극히 당위적인 논리이다.  


***~~우리의 아이(**AI**)가 현명하게 자랐으면 싶은 욕심이 있다면, 데이터 라벨링을 신경쓰기 바란다.~~***  




![the difference between detection and segmentation](https://github.com/HoonC-corgi/Convolution_Filter_Application/assets/118245330/69be1382-0dd5-4438-a3bc-6aa070c8b64d)


아무튼 데이터 라벨링은 정말 중요한 작업이다. 또, 동시에 정말 힘들고 어려운 작업이기도 하다. 데이터 라벨링의 방식은 당 모델의 Task에 따라 구분되는데, <u>Task가 Object Detection인 경우에는 특정 클래스의 위치 정보를 담고 있는 'Bounding Box'를, Instance Segmentation인 경우 'Mask' 영역을 그려주어야 한다.</u>  


가령, 모델에 사람을 학습 시킨다고 가정할 때, 모델은 사람이 나온 해당 이미지 전체가 아닌 이미지 중 사람이 나온 영역을 중심으로 학습하기를 원한다는 것이다(사람이 나온 사진 자체가 사람은 아니기 때문이다). 때문에 그 영역의 표시는 <u>최소한의 기준점 x, y와 그에 대한 width, height를 통해 만들어지는 사각형</u>으로 이루어지고, 사각형 내의 사람이 아닌 <u>배경 부분은 제거하고 정확히 사람만 학습에 사용하기 위해 누끼를 따기도 하였는데</u>, 이 사각형과 누끼를 각각 **Bounding Box**, **Mask**라 정의했다.  


정말 끔찍한 점은, 모델에 사용할 수천에서 수만 장의 데이터에 일일이 수작업을 진행해야 한다는 것이다. 따라서 최근에는 ai가 부상함에 따라 'Labeler'라는 직업이 새로 등장했다는 말도 들을 수 있었다(물론, 그들의 대부분은 회사에 소속된 직원인 경우가 많다).


처음에는 데이터 부족과 라벨링의 어려움을 이유로, 한국 지능정보 진흥원에서 운영하는 [ai hub](https://aihub.or.kr)의 공공 데이터를 사용하려 하였으나, 이는 TensorFlow, Keras 등의 프레임 워크에 적합해 보이는 라벨링 포맷이었고, json에 약한 내가 쓰기에는 어려움이 있었다.  
나는 데이터 라벨링을 위해서, [roboflow](https://roboflow.com)의 툴을 이용하여 편하게 작업했다. roboflow와 같은 툴을 이용한다면 이미지에 박스를 그리고, 누끼를 따면 레이블 파일이 생성되지만, 라벨링 툴을 사용하지 않는다면 일일이 모든 사진에 대해 아래와 같은 파일을 작성해야 한다.

![label file](https://github.com/HoonC-corgi/Convolution_Filter_Application/assets/118245330/72964e14-ffcf-456d-af21-ee0ff76a56bc)

### ***cf .***  

![labeling_after_augmentation](https://github.com/HoonC-corgi/Convolution_Filter_Application/assets/118245330/6b880aaa-9b1f-492d-8df2-47b424db0afa)

증강, 라벨링 과정 중에는 반드시 데이터 증강을 거친 후에, 라벨링을 해야 한다. 레이블된 좌표는 이미 생성되었기 때문에 원본 이미지와 동기화 되어 증강되지 않기 때문이다.

---

## data set split
#### 정의
데이터 확보가 완료되었다면, 이를 모델에 학습시키기 위한 분할을 해야 한다.  
학습에 필요한 데이터는 3가지로 구분된다.
1. **train data**
2. **validation data**
3. **test data**


각 데이터의 기능은 다음과 같다.
+ **train data**: 모델이 실제로 학습할 데이터로, 데이터 셋에서 가장 큰 비율을 가진다.
- **validation data**: train data를 통해 학습된 모델이 과적합된 것은 아닌지, 모델의 추론 결과가 높은 재현율을 가질 수 있는지에 대한 여부를 판단할 수 있다.  
가령, train data를 학습한 모델의 mAP가 0.98 - 1.0을 보이더라도, validation data에 대한 그것이 낮다면, 이는 **과적합**(모델이 train data에 대해서 지나치게 학습되어 실제 환경에서의 성능이 떨어지는 경우)을 의심해 보아야 한다(<u>과적합의 대부분은 다양한 변수를 반영하지 못하는 데이터에서 일어나며</u>, 이는 모델 학습에서 중요한 개념인 '***확증 편향***'으로 이어질 수 있다). 이러한 점에서 validation data는 이를 판단하고 해결할 수 있게 하는 인사이트를 제공하기에 정말 중요한 요소이다. 통상적으로 "val_data" 등으로 축약한다.   
***p.s.*** 처음 ai 공부를 위해 샀던 도서 '혼공머신'에서도 'cross validation', '검증 점수' 등의 개념과 함께 강조하는 중요한 개념이다.
+ **test data**: 학습된 모델을 평가하기 위한 데이터 셋으로, 전체 데이터 셋에서 가장 작은 비율을 가진다. 전술한 validation data의 추론 결과와 함께 비교하며 과적합 여부에 대한 판단할 수 있다. 모델의 성능 점수와 검증 점수의 차이가 크다면, epoch, lr(learning rate), activation function 등의 Back Bone(모델의 Cofiguration) 하이퍼 파라미터 튜닝을 시도해 볼 수 있다.

#### split 비율
data set split의 비율은 데이터의 양, 질에 따라서 차이가 날 수 있지만 통상적인 비율은 train : test = 8 : 2, train : val : test = 6 : 3(2) : 1(2) 정도이지만, 가령 100,000장의 전체 data set에서 20%만 test data여도 이는 20,000장이고, 1,000,000장의 2%여도 20,000장이 되므로 단순히 비율로만 고려해서 될 것은 아니다.  


나의 경우 전체 데이터 셋이 3,000장으로 소규모였기 때문에 train : val : test = 7 : 2 : 1의 비율으로 학습량을 늘이되, mAP, Recall이 낮을 때에는 추가적인 코드 작성을 통해 Detection하지 못한 데이터의 특징을 분석하여 데이터를 추가적으로 정제하고, 증강 기법의 변경, 하이퍼 파라미터 튜닝으로 성능 향상을 시도하였다.


---

이 과정에서 겪은 어려움과 교착지점, 노력 등에 대한 이야기는 너무 많기에 학습 데이터 준비에 관한 일지는 이정도에서 갈무리 하고, 추후 학습 과정, 결과, 분석, 응용 등의 게시글에서 그때그때 필요한 이야기를 담아보고자 한다.

---

> 역시 정도(正道)만이 살 길이다.
천천히, 그리고 꾸준히 걸어라!

---

---

***Seong Hun KIM***

**Student**  
**Dept. of Computer Science Engineering | Yeungnam University, Repulic of Korea**

![yu signature](https://github.com/HoonC-corgi/Convolution_Filter_Application/assets/118245330/37c81d9e-cfb8-4aee-8497-ff1071b2458b)

**Phone** | 010 - 6685 - 1140  
**Mail** | [tgh7544@naver.com](mailto:tgh7544@naver.com)  
**LinkTree** | [https://linktr.ee/HoonC_corgi](https://linktr.ee/HoonC_corgi)